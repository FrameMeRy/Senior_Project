{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total segments: 41060\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "def getdata():\n",
    "    es = Elasticsearch(['http://10.251.151.76:9200'])\n",
    "    \n",
    "    # Specify the time range for data selection\n",
    "    start_time = datetime.now() - timedelta(minutes=5)\n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    # Dynamically construct the index name based on the current date\n",
    "    index_date = end_time.strftime(\"%Y.%m.%d\")\n",
    "    index_name = f\"logstash-test-{index_date}\"\n",
    "    \n",
    "    scroll_size = 10000\n",
    "    search_body = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\"range\": {\"@timestamp\": {\"gte\": start_time, \"lte\": end_time}}},  # Filter by timestamp\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"size\": scroll_size,\n",
    "    }\n",
    "\n",
    "    response = es.search(index=index_name, body=search_body, scroll='100m')\n",
    "    scroll_id = response['_scroll_id']\n",
    "    results = []\n",
    "\n",
    "    while True:\n",
    "        hits = response['hits']['hits']\n",
    "        if not hits:\n",
    "            break\n",
    "        results.extend([hit['_source'] for hit in hits])\n",
    "        response = es.scroll(scroll_id=scroll_id, scroll='100m')\n",
    "    \n",
    "    # Convert the results to JSON format\n",
    "    json_results = json.dumps(results, indent=2)\n",
    "    \n",
    "    # Save the results to a file named 'data.json'\n",
    "    with open('data.json', 'w') as f:\n",
    "        f.write(json_results)\n",
    "\n",
    "getdata()\n",
    "import json\n",
    "\n",
    "segments = {}\n",
    "# ฟังก์ชันสำหรับ segment packets และแสดง feature ของแต่ละ segment\n",
    "def segment_packets(packets):\n",
    "    global segments  # เก็บ segment แต่ละอันพร้อม feature\n",
    "    for packet in packets:\n",
    "        src_ip = packet.get('srcip', None)\n",
    "        dst_ip = packet.get('dstip', None)\n",
    "        src_port = packet.get('srcport', None)\n",
    "        dst_port = packet.get('dstport', None)\n",
    "        sentbyte = int(packet.get('sentbyte', 0))  # อ่านค่า sbytes และแปลงเป็นจำนวนเต็ม\n",
    "        rcvdbyte = int(packet.get('rcvdbyte', 0))  # อ่านค่า dbytes และแปลงเป็นจำนวนเต็ม\n",
    "        sentpkt = int(packet.get('sentpkt', 0))  # อ่านค่า spkts และแปลงเป็นจำนวนเต็ม\n",
    "        rcvdpkt = int(packet.get('rcvdpkt', 0))  # อ่านค่า dpkts และแปลงเป็นจำนวนเต็ม\n",
    "        service = packet.get('service', None)\n",
    "        timestamp = packet.get('timestamp', None)  # เพิ่มการดึงค่า timestamp\n",
    "        duration = packet.get('duration', None)\n",
    "\n",
    "        segment_key = (src_ip, src_port, dst_ip, dst_port)  # กำหนด segment_key ใหม่\n",
    "\n",
    "\n",
    "        # คำนวณค่า dinpkt และ sinpkt สำหรับแต่ละ packet\n",
    "        if sentpkt > 1:\n",
    "            duration = int(duration)\n",
    "            dinpkt = duration / (sentpkt - 1)\n",
    "            packet['dinpkt'] = dinpkt\n",
    "        if rcvdpkt > 1:\n",
    "            duration = int(duration)\n",
    "            sinpkt = duration / (rcvdpkt - 1)\n",
    "            packet['sinpkt'] = sinpkt\n",
    "\n",
    "        if segment_key not in segments:\n",
    "            segments[segment_key] = {'packets': [], 'ct_srv_src': 0, 'is_sm_ips_ports': 0, 'is_ftp_login': 0, 'ct_srv_dst': 0, 'ct_dst_ltm': 0, 'ct_src_ltm': 0, 'ct_src_dport_ltm': 0, 'ct_dst_sport_ltm': 0 ,'ct_dst_src_ltm': 0,'last_timestamp': None, 'sbytes': 0, 'dbytes': 0, 'spkts': 0, 'dpkts': 0,'response_body_len': 0 }  # เพิ่ม last_timestamp, sbytes, dbytes, spkts, และ dpkts ใน segment\n",
    "        segments[segment_key]['packets'].append(packet)  # เพิ่มข้อมูลเรียบร้อย\n",
    "        \n",
    "        segments[segment_key]['sbytes'] += sentbyte  # เพิ่มขนาดของข้อมูลที่ถูกส่งออก\n",
    "        segments[segment_key]['dbytes'] += rcvdbyte  # เพิ่มขนาดของข้อมูลที่ถูกรับเข้า\n",
    "        segments[segment_key]['spkts'] += sentpkt  # เพิ่มจำนวนของแพ็กเก็ตที่ถูกส่งออก\n",
    "        segments[segment_key]['dpkts'] += rcvdpkt  # เพิ่มจำนวนของแพ็กเก็ตที่ถูกรับเข้า\n",
    "\n",
    "        segments[segment_key]['packets'].append(packet)  # เพิ่มข้อมูลเรียบร้อย\n",
    "        if timestamp and (not segments[segment_key]['last_timestamp'] or timestamp > segments[segment_key]['last_timestamp']):\n",
    "            segments[segment_key]['last_timestamp'] = timestamp  # กำหนด last_timestamp เป็น timestamp ล่าสุด\n",
    "\n",
    "    # คำนวณค่า ct_srv_src, is_sm_ips_ports, is_ftp_login, ct_srv_dst, ct_dst_ltm และ ct_src_ltm สำหรับแต่ละ segment\n",
    "    for segment, data in segments.items():\n",
    "        # คำนวณ ct_srv_src\n",
    "        service_count_src = {}\n",
    "        for packet in data['packets']:\n",
    "            src_ip = packet.get('srcip', None)\n",
    "            service_key = packet.get('service', None)\n",
    "            if service_key and src_ip:\n",
    "                connection_key = (src_ip, service_key)\n",
    "                if connection_key in service_count_src:\n",
    "                    service_count_src[connection_key] += 1\n",
    "                else:\n",
    "                    service_count_src[connection_key] = 1\n",
    "        max_count_src = max(service_count_src.values()) if service_count_src else 0\n",
    "        data['ct_srv_src'] = max_count_src if max_count_src <= 100 else 100  # ระบุค่าเท่ากับจำนวนการเชื่อมต่อสูงสุด หรือ 100 ตามเงื่อนไข\n",
    "\n",
    "        # คำนวณ is_sm_ips_ports\n",
    "        is_sm_ips_ports = 1 if segment[0] == segment[2] and segment[1] == segment[3] else 0\n",
    "        data['is_sm_ips_ports'] = is_sm_ips_ports\n",
    "        \n",
    "        # คำนวณ is_ftp_login\n",
    "        for packet in data['packets']:\n",
    "            if 'ftp' in packet.get('service', '').lower():\n",
    "                if 'user' in packet and 'pass' in packet:\n",
    "                    data['is_ftp_login'] = 1\n",
    "                    break\n",
    "\n",
    "        # คำนวณ ct_srv_dst\n",
    "        service_count_dst = {}\n",
    "        for packet in data['packets']:\n",
    "            dst_ip = packet.get('dstip', None)\n",
    "            service_key = packet.get('service', None)\n",
    "            if service_key and dst_ip:\n",
    "                connection_key = (dst_ip, service_key)\n",
    "                if connection_key in service_count_dst:\n",
    "                    service_count_dst[connection_key] += 1\n",
    "                else:\n",
    "                    service_count_dst[connection_key] = 1\n",
    "        max_count_dst = max(service_count_dst.values()) if service_count_dst else 0\n",
    "        data['ct_srv_dst'] = max_count_dst\n",
    "\n",
    "        # คำนวณ ct_dst_ltm\n",
    "        dst_count = {}\n",
    "        for packet in data['packets']:\n",
    "            dst_ip = packet.get('dstip', None)\n",
    "            if dst_ip:\n",
    "                if dst_ip in dst_count:\n",
    "                    dst_count[dst_ip] += 1\n",
    "                else:\n",
    "                    dst_count[dst_ip] = 1\n",
    "        data['ct_dst_ltm'] = len(dst_count)\n",
    "\n",
    "        # คำนวณ ct_src_ltm\n",
    "        src_count = {}\n",
    "        for packet in data['packets']:\n",
    "            src_ip = packet.get('srcip', None)\n",
    "            if src_ip:\n",
    "                if src_ip in src_count:\n",
    "                    src_count[src_ip] += 1\n",
    "                else:\n",
    "                    src_count[src_ip] = 1\n",
    "        data['ct_src_ltm'] = len(src_count)\n",
    "\n",
    "        # คำนวณ ct_src_dport_ltm\n",
    "        src_dport_count = {}\n",
    "        for packet in data['packets']:\n",
    "            src_ip = packet.get('srcip', None)\n",
    "            dst_port = packet.get('dstport', None)\n",
    "            if src_ip and dst_port:\n",
    "                connection_key = (src_ip, dst_port)\n",
    "                if connection_key in src_dport_count:\n",
    "                    src_dport_count[connection_key] += 1\n",
    "                else:\n",
    "                    src_dport_count[connection_key] = 1\n",
    "\n",
    "        ct_src_dport_ltm = sum(1 for count in src_dport_count.values() if count <= 100)\n",
    "        data['ct_src_dport_ltm'] = ct_src_dport_ltm\n",
    "\n",
    "        # คำนวณ ct_dst_sport_ltm\n",
    "        dst_sport_count = {}\n",
    "        for packet in data['packets']:\n",
    "            dst_ip = packet.get('dstip', None)\n",
    "            src_port = packet.get('srcport', None)\n",
    "            if dst_ip and src_port:\n",
    "                connection_key = (dst_ip, src_port)\n",
    "                if connection_key in dst_sport_count:\n",
    "                    dst_sport_count[connection_key] += 1\n",
    "                else:\n",
    "                    dst_sport_count[connection_key] = 1\n",
    "\n",
    "        ct_dst_sport_ltm = sum(1 for count in dst_sport_count.values() if count <= 100)\n",
    "        data['ct_dst_sport_ltm'] = ct_dst_sport_ltm\n",
    "\n",
    "        # คำนวณ ct_dst_src_ltm\n",
    "        dst_src_count = {}\n",
    "        for packet in data['packets']:\n",
    "            src_ip = packet.get('srcip', None)\n",
    "            dst_ip = packet.get('dstip', None)\n",
    "            if src_ip and dst_ip:\n",
    "                connection_key = (src_ip, dst_ip)\n",
    "                if connection_key in dst_src_count:\n",
    "                    dst_src_count[connection_key] += 1\n",
    "                else:\n",
    "                    dst_src_count[connection_key] = 1\n",
    "\n",
    "        ct_dst_src_ltm = sum(1 for count in dst_src_count.values() if count <= 100)\n",
    "        data['ct_dst_src_ltm'] = ct_dst_src_ltm\n",
    "\n",
    "        # คำนวณฟีเจอร์ response_body_len\n",
    "        response_body_len = int(packet.get('rcvdbyte', 0)) - int(packet.get('sentbyte', 0))\n",
    "        data['response_body_len'] = response_body_len\n",
    "\n",
    "    # แก้ไขส่วนการ segment_packets()\n",
    "         \n",
    "    for segment, data in segments.items():\n",
    "        total_sbytes = 0  # เพิ่มตัวแปรสำหรับเก็บค่ารวมของ sbytes\n",
    "        total_dbytes = 0  # เพิ่มตัวแปรสำหรับเก็บค่ารวมของ dbytes\n",
    "        total_spkts = 0   # เพิ่มตัวแปรสำหรับเก็บค่ารวมของ spkts\n",
    "        total_dpkts = 0   # เพิ่มตัวแปรสำหรับเก็บค่ารวมของ dpkts\n",
    "        \n",
    "        for packet in data['packets']:\n",
    "            total_sbytes += int(packet.get('sentbyte', 0))\n",
    "            total_dbytes += int(packet.get('rcvdbyte', 0))\n",
    "            total_spkts += int(packet.get('sentpkt', 0))\n",
    "            total_dpkts += int(packet.get('rcvdpkt', 0))\n",
    "        \n",
    "        data['sbytes'] = total_sbytes\n",
    "        data['dbytes'] = total_dbytes\n",
    "        data['spkts'] = total_spkts\n",
    "        data['dpkts'] = total_dpkts\n",
    "     # เพิ่ม total_packets ด้วยจำนวนของ spkts และ dpkts\n",
    "        total_packets = data['spkts'] + data['dpkts']\n",
    "        data['total_packets'] = total_packets\n",
    "    \n",
    "    # # แสดง feature ของแต่ละ segment\n",
    "    # for segment, data in segments.items():\n",
    "    #     print(\"Segment:\", segment)\n",
    "    #     print(\"dinpkt\", data['packets'][0].get('dinpkt', '0'))  # แสดงค่า dinpkt ของ packet แรกใน segment หรือ N/A หากไม่มีค่า\n",
    "    #     print(\"sinpkt\", data['packets'][0].get('sinpkt', '0'))\n",
    "    #     print(\"total_packets:\", data['total_packets'])\n",
    "    #     print(\"sbytes\", data['sbytes'])  \n",
    "    #     print(\"dbytes\", data['dbytes'])  \n",
    "    #     print(\"spkts\", data['spkts'])    \n",
    "    #     print(\"dpkts\", data['dpkts'])\n",
    "    #     print(\"ct_srv_src:\", data['ct_srv_src'])\n",
    "    #     print(\"is_sm_ips_ports:\", data['is_sm_ips_ports'])\n",
    "    #     print(\"is_ftp_login:\", data['is_ftp_login'])\n",
    "    #     print(\"ct_srv_dst:\", data['ct_srv_dst'])\n",
    "    #     print(\"ct_dst_ltm:\", data['ct_dst_ltm'])\n",
    "    #     print(\"ct_src_ltm:\", data['ct_src_ltm'])\n",
    "    #     print(\"ct_src_dport_ltm:\", data['ct_src_dport_ltm'])\n",
    "    #     print(\"ct_dst_sport_ltm:\", data['ct_dst_sport_ltm'])\n",
    "    #     print(\"ct_dst_src_ltm:\", data['ct_dst_src_ltm'])\n",
    "    #     print(\"response_body_len:\", data['response_body_len'])\n",
    "    #     # print(\"Packets:\")\n",
    "    #     # for packet in data['packets']:\n",
    "    #     #     print(json.dumps(packet, indent=4))  # แสดงข้อมูลในรูปแบบ JSON\n",
    "    #     print(\"-\" * 50)\n",
    "    # # คืนค่า dictionary ของ segments\n",
    "    return segments\n",
    "\n",
    "# ฟังก์ชันหลักสำหรับอ่านข้อมูลจากไฟล์ JSON และสร้าง packets\n",
    "def main(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    packets = []  # เก็บ packets ที่อ่านจากไฟล์ JSON\n",
    "    for entry in data:\n",
    "        packets.append(entry if entry else None)  #\n",
    "\n",
    "    segments = segment_packets(packets)\n",
    "\n",
    "    # นับและแสดงจำนวน segment ทั้งหมด\n",
    "    print(\"Total segments:\", len(segments))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"data.json\"  # ชื่อไฟล์ JSON ที่ต้องการใช้\n",
    "    main(filename)\n",
    "\n",
    "    import csv\n",
    "\n",
    "def save_segments_to_csv(segments, filename):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['dinpkt', 'sinpkt', 'sbytes', 'dbytes', 'spkts', 'dpkts', 'ct_srv_src', 'is_sm_ips_ports', 'is_ftp_login', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'response_body_len']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for segment, data in segments.items():\n",
    "            writer.writerow({\n",
    "                'dinpkt': data['packets'][0].get('dinpkt', '0'),\n",
    "                'sinpkt': data['packets'][0].get('sinpkt', '0'),\n",
    "                'sbytes': data['sbytes'],\n",
    "                'dbytes': data['dbytes'],\n",
    "                'spkts': data['spkts'],\n",
    "                'dpkts': data['dpkts'],\n",
    "                'ct_srv_src': data['ct_srv_src'],\n",
    "                'is_sm_ips_ports': data['is_sm_ips_ports'],\n",
    "                'is_ftp_login': data['is_ftp_login'],\n",
    "                'ct_srv_dst': data['ct_srv_dst'],\n",
    "                'ct_dst_ltm': data['ct_dst_ltm'],\n",
    "                'ct_src_ltm': data['ct_src_ltm'],\n",
    "                'ct_src_dport_ltm': data['ct_src_dport_ltm'],\n",
    "                'ct_dst_sport_ltm': data['ct_dst_sport_ltm'],\n",
    "                'ct_dst_src_ltm': data['ct_dst_src_ltm'],\n",
    "                'response_body_len': data['response_body_len']\n",
    "            })\n",
    "\n",
    "# เรียกใช้ฟังก์ชันเพื่อเซฟข้อมูลลงในไฟล์ CSV\n",
    "save_segments_to_csv(segments, 'segments.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total segments: 41897\n",
      "       Probability_Normal  Probability_Attack\n",
      "0                1.000000            0.000000\n",
      "1                0.940000            0.060000\n",
      "2                0.120044            0.879956\n",
      "3                1.000000            0.000000\n",
      "4                0.649980            0.350020\n",
      "...                   ...                 ...\n",
      "41892            0.590359            0.409641\n",
      "41893            0.590359            0.409641\n",
      "41894            0.590359            0.409641\n",
      "41895            0.590359            0.409641\n",
      "41896            0.372509            0.627491\n",
      "\n",
      "[41897 rows x 2 columns]\n",
      "Total segments: 52815\n",
      "       Probability_Normal  Probability_Attack\n",
      "0                1.000000            0.000000\n",
      "1                0.920000            0.080000\n",
      "2                0.120044            0.879956\n",
      "3                1.000000            0.000000\n",
      "4                0.649980            0.350020\n",
      "...                   ...                 ...\n",
      "52810            0.590359            0.409641\n",
      "52811            0.590359            0.409641\n",
      "52812            0.590359            0.409641\n",
      "52813            0.590359            0.409641\n",
      "52814            0.590359            0.409641\n",
      "\n",
      "[52815 rows x 2 columns]\n",
      "Total segments: 65300\n",
      "       Probability_Normal  Probability_Attack\n",
      "0                1.000000            0.000000\n",
      "1                0.910000            0.090000\n",
      "2                0.120044            0.879956\n",
      "3                1.000000            0.000000\n",
      "4                0.649980            0.350020\n",
      "...                   ...                 ...\n",
      "65295            0.590359            0.409641\n",
      "65296            0.590359            0.409641\n",
      "65297            0.590359            0.409641\n",
      "65298            0.590359            0.409641\n",
      "65299            0.590359            0.409641\n",
      "\n",
      "[65300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "def orchestrate_execution():\n",
    "    while True:\n",
    "        # Run Elasticsearch data retrieval\n",
    "        getdata()  \n",
    "        \n",
    "        # Process the retrieved data\n",
    "        main(\"data.json\")  \n",
    "        \n",
    "        # Save processed data to CSV\n",
    "        save_segments_to_csv(segments, 'segments.csv')  \n",
    "\n",
    "        # Load model and preprocessor\n",
    "        model_path = 'rf_classifier+FS+DS2.pkl'\n",
    "        preprocessor_path = 'preprocessor+FS+DS2.pkl'\n",
    "        rf_model = joblib.load(model_path)\n",
    "        preprocessor = joblib.load(preprocessor_path)\n",
    "\n",
    "        # Load and preprocess new data\n",
    "        new_data_path = r\"segments.csv\"\n",
    "        new_data = pd.read_csv(new_data_path)\n",
    "        new_features = ['sbytes', 'dbytes', 'spkts', 'dpkts',\n",
    "                        'response_body_len', 'sinpkt', 'dinpkt', 'is_sm_ips_ports', \n",
    "                        'is_ftp_login', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', \n",
    "                        'ct_src_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm']\n",
    "        X_test_new = new_data[new_features]\n",
    "        X_new = preprocessor.transform(X_test_new)\n",
    "\n",
    "        # Predict probabilities\n",
    "        predictions_proba = rf_model.predict_proba(X_new)\n",
    "\n",
    "        # Create DataFrame from probabilities\n",
    "        probabilities_df = pd.DataFrame(predictions_proba, columns=['Probability_Normal', 'Probability_Attack'])\n",
    "\n",
    "        # Display predictions\n",
    "        print(probabilities_df)\n",
    "\n",
    "        time.sleep(300)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    orchestrate_execution()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
